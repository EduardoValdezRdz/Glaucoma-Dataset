from random import shuffle
import glob
import numpy as np
import cv2
import h5py
from PIL import Image
import os
import random
import keras
from keras.utils import multi_gpu_model
from keras import layers
import h5py
from keras.models import Model
from keras.layers import Input, Flatten, Dense, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, Conv2DTranspose, BatchNormalization, Activation
from keras.layers.convolutional import Conv2D, Conv2DTranspose, Conv3D, Conv3DTranspose, MaxPooling3D
from keras.layers.merge import concatenate
import threading
from keras.utils import plot_model
import cv2
from keras import backend as K
from keras.utils import to_categorical
import matplotlib.pyplot as plt
import tensorflow as tf


images_rgb = 'rgb_full/*.png' #select folder of the RGB images
images_depth = 'depth_full/*.png' #select folder of the target depth maps

addrs_rgb = glob.glob(images_rgb)
addrs_depth = glob.glob(images_depth)

a = len(addrs_rgb)
b = len(addrs_depth)
print(a)
print(b)

full_data_train = addrs_rgb
full_data_labels = addrs_depth
full_data_train.sort()
full_data_labels.sort()
print(full_data_train)
print(full_data_labels)

d = list(zip(full_data_train, full_data_labels))
shuffle(d)
full_data_train, full_data_labels = zip(*d)

print(full_data_train)
print(full_data_labels)

sia = 352
sib = 352
sta = 352
stb = 352

def display_one(a, title1 = "Original"):
    plt.imshow(a), plt.title(title1)
    plt.show()

def procesar_rgb(ruta_rgb):
    imgd = Image.open(ruta_rgb)  # Replace with your image name here
    imgd = np.array(imgd)
    imgd = cv2.resize(imgd, (sib, sia))
    max_val = float(np.iinfo(imgd.dtype).max)
    imgd = imgd/max_val
    imgd = imgd.astype('float32')
    auxd = np.zeros((sia, sib, 3), np.float32)
    auxd[:, :, :] = imgd[:, :, 0:3]
    auxd = np.transpose(auxd, (2, 0, 1))
    return auxd

def procesar_depth(ruta_depth):
    imgdc = Image.open(ruta_depth)  # Replace with your image name here
    imgdc = np.array(imgdc)
    imgdc = cv2.resize(imgdc, (stb, sta))
    max_val = float(np.iinfo(imgdc.dtype).max)
    imgdc = imgdc/max_val
    imgdc = imgdc.astype('float32')
    auxdc = np.zeros((sta, stb, 1), np.float32)
    auxdc[:, :, 0] = imgdc[:, :]
    auxdc = np.transpose(auxdc, (2, 0, 1))
    return auxdc

im = procesar_depth(full_data_labels[0])
print(im)

def generator(image_file_list, depth_list, batch_size):
    i = 0
    while True:
        batch = {'images': [], 'labels': []}  # use a dict for multiple inputs
        for b in range(batch_size):
            if i == len(image_file_list):
                i = 0
            sample = image_file_list[i]
            sample1 = depth_list[i]
            image_file_path = sample
            image_file_path1 = sample1
            i += 1
            image = procesar_rgb(image_file_path)
            labels = procesar_depth(image_file_path1)
            batch['images'].append(image)
            batch['labels'].append(labels)
        batch['images'] = np.array(batch['images'])
        batch['labels'] = np.array(batch['labels'])
        yield batch['images'], batch['labels']

data_format = 'channels_first'

def l2_loss(y_true, y_pred):
    alpha = 0.001
    loss = (K.sum((y_pred-y_true)**2)/2)*alpha
    return loss

def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same", data_format=data_format)(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
        x = Activation("relu")(x)
        # second layer
        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same", data_format=data_format)(x)
    if batchnorm:
        x = BatchNormalization()(x)
        x = Activation("relu")(x)
    return x

def data_statistic(train_dataset):
    len(train_dataset)
    return len(train_dataset)

def get_unet(input_img, n_filters=32, dropout=0.5, batchnorm=True):
    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = MaxPooling2D((2, 2), data_format=data_format)(c1)
    p1 = Dropout(dropout*0.5)(p1)
    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = MaxPooling2D((2, 2), data_format=data_format)(c2)
    p2 = Dropout(dropout)(p2)
    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = MaxPooling2D((2, 2), data_format=data_format)(c3)
    p3 = Dropout(dropout)(p3)
    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = MaxPooling2D(pool_size=(2, 2), data_format=data_format)(c4)
    p4 = Dropout(dropout)(p4)
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)
    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c5)
    u6 = concatenate([u6, c4], axis=1)
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c6)
    u7 = concatenate([u7, c3], axis=1)
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c7)
    u8 = concatenate([u8, c2], axis=1)
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c8)
    u9 = concatenate([u9, c1], axis=1)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    outputs = Conv2D(1, (1, 1), activation='sigmoid', data_format=data_format)(c9)
    model = Model(inputs=[input_img], outputs=[outputs])
    return model

inputs = Input((3, sia, sib))
model = get_unet(inputs, n_filters=64, dropout=0.05, batchnorm=True)
model.compile(optimizer='adam', loss=l2_loss, metrics=["accuracy"])
model.summary()

batch_size = 5
train_generator = generator(full_data_train, full_data_labels, batch_size)
nb_train_samples = data_statistic(full_data_train)
print('train samples: %d' % nb_train_samples)

model.fit_generator(epochs=1000, generator=train_generator, steps_per_epoch=nb_train_samples // batch_size)

model_json = model.to_json()
with open('model.json', 'w') as json_file: #select folder to save the weights
    json_file.write(model_json)
model.save_weights('RNA.h5')#select folder to save the weights

